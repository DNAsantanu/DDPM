{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e73a75a",
   "metadata": {},
   "source": [
    "- import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a9d622-cc94-4a56-a245-22642b70af19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:57:19.575265Z",
     "iopub.status.busy": "2025-08-30T17:57:19.574982Z",
     "iopub.status.idle": "2025-08-30T17:58:38.837215Z",
     "shell.execute_reply": "2025-08-30T17:58:38.836263Z",
     "shell.execute_reply.started": "2025-08-30T17:57:19.575244Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-fidelity\n",
      "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (11.2.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (1.15.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torch-fidelity)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torch-fidelity)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torch-fidelity)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torch-fidelity)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torch-fidelity)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torch-fidelity)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torch-fidelity)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torch-fidelity)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torch-fidelity)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torch-fidelity)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-fidelity) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-fidelity) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-fidelity) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-fidelity) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-fidelity) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-fidelity) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-fidelity) (2024.2.0)\n",
      "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-fidelity\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-fidelity-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-fidelity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f46320f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:01:33.786716Z",
     "iopub.status.busy": "2025-08-30T18:01:33.786049Z",
     "iopub.status.idle": "2025-08-30T18:01:38.539882Z",
     "shell.execute_reply": "2025-08-30T18:01:38.539215Z",
     "shell.execute_reply.started": "2025-08-30T18:01:33.786690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torchmetrics\n",
    "import torch_fidelity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a86c1",
   "metadata": {},
   "source": [
    "- FID metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62e9536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:01:38.541653Z",
     "iopub.status.busy": "2025-08-30T18:01:38.541263Z",
     "iopub.status.idle": "2025-08-30T18:01:38.545048Z",
     "shell.execute_reply": "2025-08-30T18:01:38.544355Z",
     "shell.execute_reply.started": "2025-08-30T18:01:38.541633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "except Exception:\n",
    "    FrechetInceptionDistance = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02f7c2",
   "metadata": {},
   "source": [
    "- Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d73f0a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:01:38.546059Z",
     "iopub.status.busy": "2025-08-30T18:01:38.545749Z",
     "iopub.status.idle": "2025-08-30T18:01:38.619333Z",
     "shell.execute_reply": "2025-08-30T18:01:38.618583Z",
     "shell.execute_reply.started": "2025-08-30T18:01:38.546041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    image_size = 32\n",
    "    channels = 3\n",
    "    batch_size = 32\n",
    "    lr = 2e-4\n",
    "    epochs = 100\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    diffusion_steps = 400\n",
    "    beta_start = 1e-4\n",
    "    beta_end = 0.02\n",
    "\n",
    "    base_channels = 128\n",
    "    channel_mult = (1, 2, 2, 2)  # -> [128,256,256,256]\n",
    "    attn_resolutions = (16,)     # attention at 16x16\n",
    "    num_res_blocks = 2\n",
    "    dropout = 0.1\n",
    "\n",
    "    out_dir = \"./ddpm_original_runs_1\"\n",
    "    save_every = 400\n",
    "    sample_batch = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9245dec",
   "metadata": {},
   "source": [
    "- Beta schedule & helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9cdc313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:01:47.154816Z",
     "iopub.status.busy": "2025-08-30T18:01:47.154522Z",
     "iopub.status.idle": "2025-08-30T18:01:47.160710Z",
     "shell.execute_reply": "2025-08-30T18:01:47.159773Z",
     "shell.execute_reply.started": "2025-08-30T18:01:47.154795Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def linear_beta_schedule(timesteps, beta_start, beta_end):\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "\n",
    "def make_diffusion_series(T, beta_start, beta_end, device):\n",
    "    betas = linear_beta_schedule(T, beta_start, beta_end).to(device)\n",
    "    alphas = 1.0 - betas\n",
    "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "    alphas_cumprod_prev = torch.cat([torch.tensor([1.0], device=device), alphas_cumprod[:-1]], dim=0)\n",
    "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
    "    posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "    return {\n",
    "        \"betas\": betas,\n",
    "        \"alphas\": alphas,\n",
    "        \"alphas_cumprod\": alphas_cumprod,\n",
    "        \"sqrt_alphas_cumprod\": sqrt_alphas_cumprod,\n",
    "        \"sqrt_one_minus_alphas_cumprod\": sqrt_one_minus_alphas_cumprod,\n",
    "        \"posterior_variance\": posterior_variance\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f50f18",
   "metadata": {},
   "source": [
    "- Sinusoidal time embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29b6d962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:01:49.995761Z",
     "iopub.status.busy": "2025-08-30T18:01:49.994968Z",
     "iopub.status.idle": "2025-08-30T18:01:50.000658Z",
     "shell.execute_reply": "2025-08-30T18:01:50.000065Z",
     "shell.execute_reply.started": "2025-08-30T18:01:49.995731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def sinusoidal_positional_embedding(timesteps: torch.Tensor, dim: int):\n",
    "    assert len(timesteps.shape) == 1\n",
    "    half = dim // 2\n",
    "    freqs = torch.exp(- math.log(10000) * torch.arange(half, dtype=torch.float32, device=timesteps.device) / (half - 1))\n",
    "    args = timesteps.float().unsqueeze(1) * freqs.unsqueeze(0)\n",
    "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
    "    if dim % 2 == 1:\n",
    "        emb = F.pad(emb, (0, 1))\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8052171",
   "metadata": {},
   "source": [
    "- ResNet block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c917bd67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:01:52.283560Z",
     "iopub.status.busy": "2025-08-30T18:01:52.282853Z",
     "iopub.status.idle": "2025-08-30T18:01:52.290319Z",
     "shell.execute_reply": "2025-08-30T18:01:52.289640Z",
     "shell.execute_reply.started": "2025-08-30T18:01:52.283533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, time_emb_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_ch)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = nn.SiLU()\n",
    "        self.res_conv = nn.Conv2d(in_ch, out_ch, kernel_size=1) if in_ch != out_ch else nn.Identity()\n",
    "\n",
    "        # Lazy GroupNorms (created on first forward pass to match actual channels)\n",
    "        self.norm1 = None\n",
    "        self.norm2 = None\n",
    "\n",
    "    def forward(self, x, t_emb=None):\n",
    "        if self.norm1 is None or self.norm1.num_channels != x.size(1):\n",
    "            self.norm1 = nn.GroupNorm(8, x.size(1)).to(x.device)\n",
    "        if self.norm2 is None or self.norm2.num_channels != self.conv1.out_channels:\n",
    "            self.norm2 = nn.GroupNorm(8, self.conv1.out_channels).to(x.device)\n",
    "\n",
    "        h = self.norm1(x)\n",
    "        h = self.act(h)\n",
    "        h = self.conv1(h)\n",
    "\n",
    "        if t_emb is not None:\n",
    "            h = h + self.time_mlp(t_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        h = self.norm2(h)\n",
    "        h = self.act(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        return h + self.res_conv(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe2e73",
   "metadata": {},
   "source": [
    "- Attention block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60152a13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:01:55.115055Z",
     "iopub.status.busy": "2025-08-30T18:01:55.114503Z",
     "iopub.status.idle": "2025-08-30T18:01:55.121547Z",
     "shell.execute_reply": "2025-08-30T18:01:55.120362Z",
     "shell.execute_reply.started": "2025-08-30T18:01:55.115033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, ch, num_heads=4):\n",
    "        super().__init__()\n",
    "        assert ch % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.norm = nn.GroupNorm(8, ch)\n",
    "        self.q = nn.Conv2d(ch, ch, 1)\n",
    "        self.k = nn.Conv2d(ch, ch, 1)\n",
    "        self.v = nn.Conv2d(ch, ch, 1)\n",
    "        self.proj_out = nn.Conv2d(ch, ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.norm(x)\n",
    "        q = self.q(h).view(B, self.num_heads, C // self.num_heads, H * W)\n",
    "        k = self.k(h).view(B, self.num_heads, C // self.num_heads, H * W)\n",
    "        v = self.v(h).view(B, self.num_heads, C // self.num_heads, H * W)\n",
    "        scale = 1.0 / math.sqrt(C // self.num_heads)\n",
    "        attn = torch.einsum('bhdn,bhdm->bhnm', q, k) * scale\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        out = torch.einsum('bhnm,bhdm->bhdn', attn, v)\n",
    "        out = out.contiguous().view(B, C, H, W)\n",
    "        out = self.proj_out(out)\n",
    "        return x + out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c459aa20",
   "metadata": {},
   "source": [
    "- UNet model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd76522a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:01:57.588859Z",
     "iopub.status.busy": "2025-08-30T18:01:57.588281Z",
     "iopub.status.idle": "2025-08-30T18:01:57.604050Z",
     "shell.execute_reply": "2025-08-30T18:01:57.603145Z",
     "shell.execute_reply.started": "2025-08-30T18:01:57.588837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class OriginalDDPMUNet(nn.Module):\n",
    "    def __init__(self, in_ch=3, base_ch=128, channel_mult=(1,2,2,2),\n",
    "                 attn_resolutions=(16,), num_res_blocks=2, dropout=0.1, time_emb_dim=256):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_emb_dim, time_emb_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim)\n",
    "        )\n",
    "\n",
    "        self.init_conv = nn.Conv2d(in_ch, base_ch, kernel_size=3, padding=1)\n",
    "\n",
    "        # compute channel list per level\n",
    "        chs = [base_ch * m for m in channel_mult]  # e.g. [128,256,256,256]\n",
    "        in_out = list(zip([base_ch] + chs[:-1], chs))\n",
    "\n",
    "        # Down path (we record skip channel sizes)\n",
    "        self.down_blocks = nn.ModuleList()\n",
    "        self.skip_channels = []\n",
    "        curr_res = CFG.image_size\n",
    "        for i, (lvl_in, lvl_out) in enumerate(in_out):\n",
    "            block_layers = nn.ModuleList()\n",
    "            attn_layers = nn.ModuleList()\n",
    "            for j in range(num_res_blocks):\n",
    "                in_ch_block = lvl_in if j == 0 else lvl_out\n",
    "                block_layers.append(ResnetBlock(in_ch_block, lvl_out, time_emb_dim, dropout))\n",
    "            if curr_res in attn_resolutions:\n",
    "                attn_layers.append(AttentionBlock(lvl_out))\n",
    "            down_sample = nn.Conv2d(lvl_out, lvl_out, kernel_size=3, stride=2, padding=1) if i < len(in_out)-1 else nn.Identity()\n",
    "            self.down_blocks.append(nn.ModuleList([block_layers, attn_layers, down_sample]))\n",
    "            self.skip_channels.append(lvl_out)\n",
    "            curr_res //= 2\n",
    "\n",
    "        # Middle\n",
    "        mid_ch = chs[-1]\n",
    "        self.mid_block1 = ResnetBlock(mid_ch, mid_ch, time_emb_dim, dropout)\n",
    "        self.mid_attn = AttentionBlock(mid_ch)\n",
    "        self.mid_block2 = ResnetBlock(mid_ch, mid_ch, time_emb_dim, dropout)\n",
    "\n",
    "        # Up path: build using recorded skip_channels in reverse\n",
    "        self.up_blocks = nn.ModuleList()\n",
    "        curr_ch = mid_ch\n",
    "        # spatial resolution at the bottleneck\n",
    "        curr_res = max(1, CFG.image_size // (2 ** (len(chs)-1)))\n",
    "\n",
    "        # Use reversed skip_channels so we pop them in the same order in forward\n",
    "        rev_skip_chs = list(reversed(self.skip_channels))  # e.g. [lvl3, lvl2, lvl1, lvl0]\n",
    "        for i, skip_ch in enumerate(rev_skip_chs):\n",
    "            block_layers = nn.ModuleList()\n",
    "            attn_layers = nn.ModuleList()\n",
    "\n",
    "            # first block consumes concatenated channels: curr_ch + skip_ch -> skip_ch\n",
    "            block_layers.append(ResnetBlock(curr_ch + skip_ch, skip_ch, time_emb_dim, dropout))\n",
    "            # subsequent blocks (if any) are skip_ch -> skip_ch\n",
    "            for _ in range(num_res_blocks):\n",
    "                block_layers.append(ResnetBlock(skip_ch, skip_ch, time_emb_dim, dropout))\n",
    "\n",
    "            if curr_res in attn_resolutions:\n",
    "                attn_layers.append(AttentionBlock(skip_ch))\n",
    "\n",
    "            # upsample that preserves channel count of \"h\" (curr_ch)\n",
    "            # For the last iteration (when we've reached the highest resolution), we DON'T upsample\n",
    "            if i < len(rev_skip_chs) - 1:\n",
    "                up_sample = nn.ConvTranspose2d(curr_ch, curr_ch, kernel_size=4, stride=2, padding=1)\n",
    "            else:\n",
    "                up_sample = nn.Identity()\n",
    "\n",
    "            self.up_blocks.append(nn.ModuleList([block_layers, attn_layers, up_sample]))\n",
    "\n",
    "            # after this level, h will have channels = skip_ch\n",
    "            curr_ch = skip_ch\n",
    "            curr_res *= 2\n",
    "\n",
    "        # final layers (GroupNorm -> SiLU -> Conv)\n",
    "        # After the final up-block the number of channels equals `base_ch`,\n",
    "        # so final_norm should use base_ch groups/channels and final_conv maps\n",
    "        # back to the input image channels (e.g. 3 for RGB).\n",
    "        self.final_norm = nn.GroupNorm(8, base_ch)\n",
    "        self.final_act = nn.SiLU()\n",
    "        self.final_conv = nn.Conv2d(base_ch, in_ch, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_emb = sinusoidal_positional_embedding(t, self.time_mlp[0].in_features)\n",
    "        t_emb = self.time_mlp(t_emb)\n",
    "\n",
    "        h = self.init_conv(x)\n",
    "        skips: List[torch.Tensor] = []\n",
    "\n",
    "        for block_layers, attn_layers, down_sample in self.down_blocks:\n",
    "            for block in block_layers:\n",
    "                h = block(h, t_emb)\n",
    "            for attn in attn_layers:\n",
    "                h = attn(h)\n",
    "            skips.append(h)\n",
    "            h = down_sample(h)\n",
    "\n",
    "        h = self.mid_block1(h, t_emb)\n",
    "        h = self.mid_attn(h)\n",
    "        h = self.mid_block2(h, t_emb)\n",
    "\n",
    "        # up path: pop skips in reverse order\n",
    "        for block_layers, attn_layers, up_sample in self.up_blocks:\n",
    "            h = up_sample(h)\n",
    "            if len(skips) == 0:\n",
    "                raise RuntimeError(\"Skip stack empty — mismatch between down and up blocks.\")\n",
    "            skip = skips.pop()\n",
    "            if h.shape[2:] != skip.shape[2:]:\n",
    "                skip = F.interpolate(skip, size=h.shape[2:], mode='nearest')\n",
    "            h = torch.cat([h, skip], dim=1)  # concatenated channels match first ResnetBlock constructor\n",
    "            for block in block_layers:\n",
    "                h = block(h, t_emb)\n",
    "            for attn in attn_layers:\n",
    "                h = attn(h)\n",
    "\n",
    "        h = self.final_norm(h)\n",
    "        h = self.final_act(h)\n",
    "        out = self.final_conv(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be108bcc",
   "metadata": {},
   "source": [
    "- Dataloader ( I have not used any data augmentation which has been used in the paper e.g. horizontal flipping )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b053458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:02:01.658482Z",
     "iopub.status.busy": "2025-08-30T18:02:01.657775Z",
     "iopub.status.idle": "2025-08-30T18:02:01.662863Z",
     "shell.execute_reply": "2025-08-30T18:02:01.662018Z",
     "shell.execute_reply.started": "2025-08-30T18:02:01.658455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, image_size, train=True):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "    ])\n",
    "    ds = torchvision.datasets.CIFAR10(root='./data', train=train, download=True, transform=transform)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=train, num_workers=2, pin_memory=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e158ee",
   "metadata": {},
   "source": [
    "- q_sample & p_sample_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e9116b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:02:04.656489Z",
     "iopub.status.busy": "2025-08-30T18:02:04.655945Z",
     "iopub.status.idle": "2025-08-30T18:02:04.664397Z",
     "shell.execute_reply": "2025-08-30T18:02:04.663592Z",
     "shell.execute_reply.started": "2025-08-30T18:02:04.656464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def q_sample(x0: torch.Tensor, t: torch.LongTensor, noise: torch.Tensor, series):\n",
    "    sqrt_ac = series['sqrt_alphas_cumprod'][t].view(-1,1,1,1)\n",
    "    sqrt_om = series['sqrt_one_minus_alphas_cumprod'][t].view(-1,1,1,1)\n",
    "    return sqrt_ac * x0 + sqrt_om * noise\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def p_sample_loop(model: nn.Module, shape: Tuple[int,int,int,int], series, device, progress=False):\n",
    "    model.eval()\n",
    "    B = shape[0]\n",
    "    x = torch.randn(shape, device=device)\n",
    "    T = series['betas'].shape[0]\n",
    "    rng = range(T-1, -1, -1)\n",
    "    if progress:\n",
    "        rng = tqdm(rng, desc='sampling')\n",
    "    for t in rng:\n",
    "        t_tensor = torch.full((B,), t, dtype=torch.long, device=device)\n",
    "        eps_pred = model(x, t_tensor)\n",
    "\n",
    "        beta_t = series['betas'][t]\n",
    "        alpha_t = series['alphas'][t]\n",
    "        alpha_cumprod_t = series['alphas_cumprod'][t]\n",
    "\n",
    "        x0_pred = (x - torch.sqrt(1 - alpha_cumprod_t) * eps_pred) / torch.sqrt(alpha_cumprod_t)\n",
    "\n",
    "        if t > 0:\n",
    "            posterior_var = series['posterior_variance'][t]\n",
    "            mean = ((beta_t * torch.sqrt(series['alphas_cumprod'][t-1]) / (1.0 - alpha_cumprod_t)) * x0_pred\n",
    "                    + ((1.0 - series['alphas_cumprod'][t-1]) * torch.sqrt(alpha_t) / (1.0 - alpha_cumprod_t)) * x)\n",
    "            noise = torch.randn_like(x)\n",
    "            x = mean + torch.sqrt(posterior_var) * noise\n",
    "        else:\n",
    "            mean = ((beta_t * torch.sqrt(series['alphas_cumprod'][t-1]) / (1.0 - alpha_cumprod_t)) * x0_pred\n",
    "                    + ((1.0 - series['alphas_cumprod'][t-1]) * torch.sqrt(alpha_t) / (1.0 - alpha_cumprod_t)) * x)\n",
    "            x = mean\n",
    "\n",
    "    x = torch.clamp(x, -1.0, 1.0)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738bb33e",
   "metadata": {},
   "source": [
    "- FID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22aef8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:02:07.391021Z",
     "iopub.status.busy": "2025-08-30T18:02:07.390331Z",
     "iopub.status.idle": "2025-08-30T18:02:07.397693Z",
     "shell.execute_reply": "2025-08-30T18:02:07.396896Z",
     "shell.execute_reply.started": "2025-08-30T18:02:07.390993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_fid(model: nn.Module, series, device, num_gen=5000, batch_size=128):\n",
    "    if FrechetInceptionDistance is None:\n",
    "        print('torchmetrics FID not available; skipping FID.')\n",
    "        return None\n",
    "    print(f'Computing FID with {num_gen} generated images (batch_size {batch_size})...')\n",
    "    fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "    real_loader = get_dataloader(batch_size=batch_size, image_size=CFG.image_size, train=True)\n",
    "    real_count = 0\n",
    "    for x_real, _ in tqdm(real_loader, desc='Updating FID with real images'):\n",
    "        x_real = x_real.to(device)\n",
    "        imgs_uint8 = ((x_real.clamp(-1,1)+1.0)/2.0*255.0).to(torch.uint8)\n",
    "        fid.update(imgs_uint8, real=True)\n",
    "        real_count += imgs_uint8.shape[0]\n",
    "        if real_count >= num_gen:\n",
    "            break\n",
    "    gen_count = 0\n",
    "    gen_bs = min(batch_size, 64)\n",
    "    while gen_count < num_gen:\n",
    "        to_gen = min(gen_bs, num_gen - gen_count)\n",
    "        samples = p_sample_loop(model, (to_gen, CFG.channels, CFG.image_size, CFG.image_size), series, device, progress=False)\n",
    "        imgs_uint8 = ((samples.clamp(-1,1)+1.0)/2.0*255.0).to(torch.uint8)\n",
    "        fid.update(imgs_uint8, real=False)\n",
    "        gen_count += imgs_uint8.shape[0]\n",
    "        print(f'Generated {gen_count}/{num_gen} for FID', end='')\n",
    "    result = fid.compute().item()\n",
    "    print(f'FID: {result:.4f}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3668d661",
   "metadata": {},
   "source": [
    "- Training loop ( There is two training loops 1st i have used for saving the models after each epoch and the 2nd only after 10 epochs and generate the images(and compute the FID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb067f",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     os.makedirs(CFG.out_dir, exist_ok=True)\n",
    "#     loader = get_dataloader(CFG.batch_size, CFG.image_size, train=True)\n",
    "\n",
    "#     model = OriginalDDPMUNet(\n",
    "#         in_ch=CFG.channels,\n",
    "#         base_ch=CFG.base_channels,\n",
    "#         channel_mult=CFG.channel_mult,\n",
    "#         attn_resolutions=CFG.attn_resolutions,\n",
    "#         num_res_blocks=CFG.num_res_blocks,\n",
    "#         dropout=CFG.dropout\n",
    "#     ).to(CFG.device)\n",
    "\n",
    "#     opt = optim.Adam(model.parameters(), lr=CFG.lr)\n",
    "#     series = make_diffusion_series(CFG.diffusion_steps, CFG.beta_start, CFG.beta_end, CFG.device)\n",
    "\n",
    "#     global_step = 0\n",
    "#     print('Training on', CFG.device)\n",
    "#     print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "\n",
    "#     for epoch in range(CFG.epochs):\n",
    "#         model.train()\n",
    "#         pbar = tqdm(loader, desc=f'Epoch {epoch+1}/{CFG.epochs}')\n",
    "#         for x, _ in pbar:\n",
    "#             x = x.to(CFG.device)\n",
    "#             b = x.shape[0]\n",
    "#             t = torch.randint(0, CFG.diffusion_steps, (b,), device=CFG.device, dtype=torch.long)\n",
    "#             noise = torch.randn_like(x)\n",
    "#             x_t = q_sample(x, t, noise, series)\n",
    "\n",
    "#             eps_pred = model(x_t, t)\n",
    "#             loss = F.mse_loss(eps_pred, noise)\n",
    "\n",
    "#             opt.zero_grad()\n",
    "#             loss.backward()\n",
    "#             opt.step()\n",
    "\n",
    "#             global_step += 1\n",
    "#             pbar.set_postfix({'loss': float(loss.item()), 'step': global_step})\n",
    "\n",
    "#             if global_step % CFG.save_every == 0:\n",
    "#                 model.eval()\n",
    "#                 with torch.no_grad():\n",
    "#                     samples = p_sample_loop(model, (CFG.sample_batch, CFG.channels, CFG.image_size, CFG.image_size), series, CFG.device, progress=False)\n",
    "#                     grid = (samples + 1.0) / 2.0\n",
    "#                     save_path = Path(CFG.out_dir) / f'samples_step_{global_step}.png'\n",
    "#                     save_image(grid, str(save_path), nrow=4)\n",
    "#                     print(f'Saved samples to {save_path}')\n",
    "#                 model.train()\n",
    "\n",
    "#         # epoch checkpoint & sample\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             samples = p_sample_loop(model, (CFG.sample_batch, CFG.channels, CFG.image_size, CFG.image_size), series, CFG.device, progress=False)\n",
    "#             grid = (samples + 1.0) / 2.0\n",
    "#             save_path = Path(CFG.out_dir) / f'samples_epoch_{epoch+1}.png'\n",
    "#             save_image(grid, str(save_path), nrow=4)\n",
    "#             print(f'Saved epoch samples to {save_path}')\n",
    "\n",
    "#         ckpt = Path(CFG.out_dir) / f'ddpm_original_epoch_{epoch+1}.pt'\n",
    "#         torch.save({'model': model.state_dict(), 'opt': opt.state_dict(), 'epoch': epoch+1}, ckpt)\n",
    "#         print(f'Saved checkpoint {ckpt}')\n",
    "#         model.train()\n",
    "\n",
    "#     print('Training finished.')\n",
    "#     return model, series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c4324fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T18:02:12.278854Z",
     "iopub.status.busy": "2025-08-30T18:02:12.278582Z",
     "iopub.status.idle": "2025-08-30T18:02:12.288100Z",
     "shell.execute_reply": "2025-08-30T18:02:12.287336Z",
     "shell.execute_reply.started": "2025-08-30T18:02:12.278832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    os.makedirs(CFG.out_dir, exist_ok=True)\n",
    "    loader = get_dataloader(CFG.batch_size, CFG.image_size, train=True)\n",
    "\n",
    "    model = OriginalDDPMUNet(\n",
    "        in_ch=CFG.channels,\n",
    "        base_ch=CFG.base_channels,\n",
    "        channel_mult=CFG.channel_mult,\n",
    "        attn_resolutions=CFG.attn_resolutions,\n",
    "        num_res_blocks=CFG.num_res_blocks,\n",
    "        dropout=CFG.dropout\n",
    "    ).to(CFG.device)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=CFG.lr)\n",
    "    series = make_diffusion_series(CFG.diffusion_steps, CFG.beta_start, CFG.beta_end, CFG.device)\n",
    "\n",
    "    global_step = 0\n",
    "    print('Training on', CFG.device)\n",
    "    print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        model.train()\n",
    "        pbar = tqdm(loader, desc=f'Epoch {epoch+1}/{CFG.epochs}')\n",
    "        for x, _ in pbar:\n",
    "            x = x.to(CFG.device)\n",
    "            b = x.shape[0]\n",
    "            t = torch.randint(0, CFG.diffusion_steps, (b,), device=CFG.device, dtype=torch.long)\n",
    "            noise = torch.randn_like(x)\n",
    "            x_t = q_sample(x, t, noise, series)\n",
    "\n",
    "            eps_pred = model(x_t, t)\n",
    "            loss = F.mse_loss(eps_pred, noise)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            global_step += 1\n",
    "            pbar.set_postfix({'loss': float(loss.item()), 'step': global_step})\n",
    "\n",
    "        # -------------------------\n",
    "        # Save & evaluate every 10 epochs\n",
    "        # -------------------------\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # Generate samples\n",
    "                samples = p_sample_loop(\n",
    "                    model, (CFG.sample_batch, CFG.channels, CFG.image_size, CFG.image_size),\n",
    "                    series, CFG.device, progress=False\n",
    "                )\n",
    "                grid = (samples + 1.0) / 2.0\n",
    "\n",
    "                # Compute FID\n",
    "                fid_score = evaluate_fid(model, series, CFG.device, num_gen=2000, batch_size=128)\n",
    "\n",
    "                # Save image with FID in filename\n",
    "                save_path = Path(CFG.out_dir) / f'samples_epoch_{epoch+1}_fid{fid_score:.2f}.png'\n",
    "                save_image(grid, str(save_path), nrow=4)\n",
    "                print(f'Saved epoch {epoch+1} samples with FID={fid_score:.2f} -> {save_path}')\n",
    "\n",
    "            # Save checkpoint\n",
    "            ckpt = Path(CFG.out_dir) / f'ddpm_original_epoch_{epoch+1}.pt'\n",
    "            torch.save({'model': model.state_dict(), 'opt': opt.state_dict(), 'epoch': epoch+1}, ckpt)\n",
    "            print(f'Saved checkpoint {ckpt}')\n",
    "            model.train()\n",
    "\n",
    "    print('Training finished.')\n",
    "    return model, series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6556ae",
   "metadata": {},
   "source": [
    "- Seed everything for repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bce1c6",
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-31T05:18:33.662Z",
     "iopub.execute_input": "2025-08-30T18:02:17.282576Z",
     "iopub.status.busy": "2025-08-30T18:02:17.282029Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Model parameters: 30,471,427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 1563/1563 [10:00<00:00,  2.60it/s, loss=0.0427, step=1563]\n",
      "Epoch 2/100: 100%|██████████| 1563/1563 [10:10<00:00,  2.56it/s, loss=0.122, step=3126] \n",
      "Epoch 3/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.026, step=4689] \n",
      "Epoch 4/100: 100%|██████████| 1563/1563 [10:11<00:00,  2.56it/s, loss=0.0706, step=6252]\n",
      "Epoch 5/100: 100%|██████████| 1563/1563 [10:12<00:00,  2.55it/s, loss=0.0397, step=7815]\n",
      "Epoch 6/100: 100%|██████████| 1563/1563 [10:10<00:00,  2.56it/s, loss=0.0622, step=9378]\n",
      "Epoch 7/100: 100%|██████████| 1563/1563 [10:11<00:00,  2.56it/s, loss=0.0627, step=10941]\n",
      "Epoch 8/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0585, step=12504]\n",
      "Epoch 9/100: 100%|██████████| 1563/1563 [10:12<00:00,  2.55it/s, loss=0.0594, step=14067]\n",
      "Epoch 10/100: 100%|██████████| 1563/1563 [10:12<00:00,  2.55it/s, loss=0.0429, step=15630]\n",
      "Epoch 11/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.058, step=17193] \n",
      "Epoch 12/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0611, step=18756]\n",
      "Epoch 13/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0791, step=20319]\n",
      "Epoch 14/100: 100%|██████████| 1563/1563 [10:15<00:00,  2.54it/s, loss=0.0348, step=21882]\n",
      "Epoch 15/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0701, step=23445]\n",
      "Epoch 16/100: 100%|██████████| 1563/1563 [10:15<00:00,  2.54it/s, loss=0.0781, step=25008]\n",
      "Epoch 17/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0931, step=26571]\n",
      "Epoch 18/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0604, step=28134]\n",
      "Epoch 19/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0375, step=29697]\n",
      "Epoch 20/100: 100%|██████████| 1563/1563 [10:15<00:00,  2.54it/s, loss=0.0251, step=31260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing FID with 2000 generated images (batch_size 128)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/toshas/torch-fidelity/releases/download/v0.2.0/weights-inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth\n",
      "100%|██████████| 91.2M/91.2M [00:00<00:00, 287MB/s] \n",
      "Updating FID with real images:   4%|▍         | 15/391 [00:08<03:22,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 64/2000 for FIDGenerated 128/2000 for FIDGenerated 192/2000 for FIDGenerated 256/2000 for FIDGenerated 320/2000 for FIDGenerated 384/2000 for FIDGenerated 448/2000 for FIDGenerated 512/2000 for FIDGenerated 576/2000 for FIDGenerated 640/2000 for FIDGenerated 704/2000 for FIDGenerated 768/2000 for FIDGenerated 832/2000 for FIDGenerated 896/2000 for FIDGenerated 960/2000 for FIDGenerated 1024/2000 for FIDGenerated 1088/2000 for FIDGenerated 1152/2000 for FIDGenerated 1216/2000 for FIDGenerated 1280/2000 for FIDGenerated 1344/2000 for FIDGenerated 1408/2000 for FIDGenerated 1472/2000 for FIDGenerated 1536/2000 for FIDGenerated 1600/2000 for FIDGenerated 1664/2000 for FIDGenerated 1728/2000 for FIDGenerated 1792/2000 for FIDGenerated 1856/2000 for FIDGenerated 1920/2000 for FIDGenerated 1984/2000 for FIDGenerated 2000/2000 for FIDFID: 214.4690\n",
      "Saved epoch 20 samples with FID=214.47 -> ddpm_original_runs_1/samples_epoch_20_fid214.47.png\n",
      "Saved checkpoint ddpm_original_runs_1/ddpm_original_epoch_20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 1563/1563 [10:11<00:00,  2.56it/s, loss=0.0429, step=32823]\n",
      "Epoch 22/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0731, step=34386]\n",
      "Epoch 23/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0653, step=35949]\n",
      "Epoch 24/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0353, step=37512]\n",
      "Epoch 25/100: 100%|██████████| 1563/1563 [10:15<00:00,  2.54it/s, loss=0.0742, step=39075]\n",
      "Epoch 26/100: 100%|██████████| 1563/1563 [10:12<00:00,  2.55it/s, loss=0.0279, step=40638]\n",
      "Epoch 27/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0341, step=42201]\n",
      "Epoch 28/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0542, step=43764]\n",
      "Epoch 29/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0465, step=45327]\n",
      "Epoch 30/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0608, step=46890]\n",
      "Epoch 31/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0657, step=48453]\n",
      "Epoch 32/100: 100%|██████████| 1563/1563 [10:15<00:00,  2.54it/s, loss=0.0301, step=5e+4] \n",
      "Epoch 33/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0761, step=51579]\n",
      "Epoch 34/100: 100%|██████████| 1563/1563 [10:12<00:00,  2.55it/s, loss=0.0519, step=53142]\n",
      "Epoch 35/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0519, step=54705]\n",
      "Epoch 36/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0365, step=56268]\n",
      "Epoch 37/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0432, step=57831]\n",
      "Epoch 38/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.035, step=59394] \n",
      "Epoch 39/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0876, step=60957]\n",
      "Epoch 40/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0515, step=62520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing FID with 2000 generated images (batch_size 128)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating FID with real images:   4%|▍         | 15/391 [00:08<03:20,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 64/2000 for FIDGenerated 128/2000 for FIDGenerated 192/2000 for FIDGenerated 256/2000 for FIDGenerated 320/2000 for FIDGenerated 384/2000 for FIDGenerated 448/2000 for FIDGenerated 512/2000 for FIDGenerated 576/2000 for FIDGenerated 640/2000 for FIDGenerated 704/2000 for FIDGenerated 768/2000 for FIDGenerated 832/2000 for FIDGenerated 896/2000 for FIDGenerated 960/2000 for FIDGenerated 1024/2000 for FIDGenerated 1088/2000 for FIDGenerated 1152/2000 for FIDGenerated 1216/2000 for FIDGenerated 1280/2000 for FIDGenerated 1344/2000 for FIDGenerated 1408/2000 for FIDGenerated 1472/2000 for FIDGenerated 1536/2000 for FIDGenerated 1600/2000 for FIDGenerated 1664/2000 for FIDGenerated 1728/2000 for FIDGenerated 1792/2000 for FIDGenerated 1856/2000 for FIDGenerated 1920/2000 for FIDGenerated 1984/2000 for FIDGenerated 2000/2000 for FIDFID: 240.9081\n",
      "Saved epoch 40 samples with FID=240.91 -> ddpm_original_runs_1/samples_epoch_40_fid240.91.png\n",
      "Saved checkpoint ddpm_original_runs_1/ddpm_original_epoch_40.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0457, step=64083]\n",
      "Epoch 42/100: 100%|██████████| 1563/1563 [10:13<00:00,  2.55it/s, loss=0.0346, step=65646]\n",
      "Epoch 43/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.55it/s, loss=0.0268, step=67209]\n",
      "Epoch 44/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.073, step=68772] \n",
      "Epoch 45/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.034, step=70335] \n",
      "Epoch 46/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0449, step=71898]\n",
      "Epoch 47/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0596, step=73461]\n",
      "Epoch 48/100: 100%|██████████| 1563/1563 [10:14<00:00,  2.54it/s, loss=0.0371, step=75024]\n",
      "Epoch 49/100:  65%|██████▌   | 1021/1563 [06:41<03:33,  2.54it/s, loss=0.0314, step=76046]"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "model, series = train()\n",
    "\n",
    "    # Final sampling after training\n",
    "with torch.no_grad():\n",
    "    samples = p_sample_loop(\n",
    "        model,\n",
    "        (CFG.sample_batch, CFG.channels, CFG.image_size, CFG.image_size),\n",
    "        series,\n",
    "        CFG.device,\n",
    "        progress=True\n",
    "        )\n",
    "    grid = (samples + 1.0) / 2.0\n",
    "    save_image(grid, str(Path(CFG.out_dir) / \"final_samples_128.png\"), nrow=4)\n",
    "    print(\"Saved final samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f147b-e3ba-4b64-b155-21baf890e88d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
